{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piratesdragon/homework_actual_problems/blob/main/homework_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dba7c0d",
      "metadata": {
        "id": "1dba7c0d"
      },
      "source": [
        "# Домашнее задание № 10. Генерация текста"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f21d5e",
      "metadata": {
        "id": "76f21d5e"
      },
      "source": [
        "### Задание 1 (8 баллов).\n",
        "\n",
        "Попробуйте дообучать GPT на каком-то другом тексте (можете попробовать любые стихи или какие-то специфичные вещи вроде анекдотов или репа). \n",
        "Попробуйте разные методы и параметры генерации (beam search, температура, top_k и тп). Сохраните в тетрадке несколько хороших сгенерированных текстов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2444e3fe",
      "metadata": {
        "id": "2444e3fe"
      },
      "outputs": [],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f07bd89b",
      "metadata": {
        "id": "f07bd89b"
      },
      "outputs": [],
      "source": [
        "from transformers.utils import logging\n",
        "logging.set_verbosity(40)\n",
        "\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "DEVICE = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель от сбера\n",
        "model_name_or_path = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name_or_path, use_cache=False).to(DEVICE)"
      ],
      "metadata": {
        "id": "KX8J9g8UoNtj"
      },
      "id": "KX8J9g8UoNtj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вредные советы Григория Остера :)\n",
        "\n",
        "text = \"\"\"\n",
        "\tПотерявшийся ребенок\n",
        "     Должен помнить, что его\n",
        "     Отведут домой, как только\n",
        "     Назовет он адрес свой.\n",
        "     Надо действовать умнее,\n",
        "     Говорите: \"Я живу Возле пальмы с обезьяной На далеких островах\".\n",
        "     Потерявшийся ребенок,\n",
        "     Если он не дурачок,\n",
        "     Не упустит верный случай\n",
        "     В разных странах побывать.\n",
        "\n",
        "     Рукам никогда нигде\n",
        "     Не трогай ничего.\n",
        "     Не впутывайся ни во что\n",
        "     И никуда не лезь.\n",
        "     В сторонку молча отойди,\n",
        "     Стань скромно в уголке\n",
        "     И тихо стой, не шевелясь,\n",
        "     До старости своей.\n",
        "\n",
        "     Кто не прыгал из окошка\n",
        "     Вместе с маминым зонтом,\n",
        "     Тот лихим парашютистом\n",
        "     Не считается пока.\n",
        "     Не лететь ему, как птице,\n",
        "     Над взволнованной толпой,\n",
        "     Не лежать ему в больнице\n",
        "     С забинтованной ногой.\n",
        "\n",
        "     Если всей семьей купаться\n",
        "     Вы отправились к реке,\n",
        "     Не мешайте папе с мамой\n",
        "     Загорать на берегу.\n",
        "     Не устраивайте крика,\n",
        "     Дайте взрослым отдохнуть.\n",
        "     Ни к кому не приставая,\n",
        "     Постарайтесь утонуть.\n",
        "\n",
        "\n",
        "     Нет приятнее занятья,\n",
        "     Чем в носу поковырять.\n",
        "     Всем ужасно интересно,\n",
        "     Что там спрятано внутри.\n",
        "     А кому смотреть противно,\n",
        "     Тот пускай и не глядит.\n",
        "     Мы же в нос к нему не лезем,\n",
        "     Пусть и он не пристает.\n",
        "     Если вас поймала мама\n",
        "     За любимым делом вашим,\n",
        "     Например, за рисованьем\n",
        "     В коридоре на обоях,\n",
        "     Объясните ей, что это -\n",
        "     Ваш сюрприз к Восьмому марта.\n",
        "     Называется картина:\n",
        "     \"Милой мамочки портрет\".\n",
        "\n",
        "\n",
        "     Не бери чужое, если\n",
        "     На тебя глядят чужие.\n",
        "     Пусть они глаза закроют\n",
        "     Или выйдут на часок.\n",
        "     А своих чего бояться!\n",
        "     Про своих свои не скажут.\n",
        "     Пусть глядят. Хватай чужое\n",
        "     И тащи его к своим.\n",
        "\n",
        "\n",
        "     Никогда вопросов глупых\n",
        "     Сам себе не задавай,\n",
        "     А не то еще глупее\n",
        "     Ты найдешь на них ответ.\n",
        "     Если глупые вопросы\n",
        "     Появились в голове,\n",
        "     Задавай их сразу взрослым.\n",
        "     Пусть у них трещат мозги.\n",
        "\n",
        "\n",
        "     Посещайте почаще\n",
        "     Театральный буфет.\n",
        "     Там пирожные с кремом,\n",
        "     С пузырьками вода.\n",
        "     Как дрова на тарелках\n",
        "     Шоколадки лежат,\n",
        "     И сквозь трубочку можно\n",
        "     Пить молочный коктейль.\n",
        "     Не просите билеты\n",
        "     На балкон и в партер,\n",
        "     Пусть дадут вам билеты\n",
        "     В театральный буфет.\n",
        "     Уходя из театра,\n",
        "     Унесете с собой\n",
        "     Под трепещущим сердцем,\n",
        "     В животе, бутерброд.\n",
        "\n",
        "\n",
        "     Родился девочкой - терпи\n",
        "     Подножки и толчки.\n",
        "     И подставляй косички всем,\n",
        "     Кто дернуть их не прочь.\n",
        "     Зато когда-нибудь потом\n",
        "     Покажешь кукиш им\n",
        "     И скажешь: \"Фигушки, за вас\n",
        "     Я замуж не пойду!\"\n",
        "\n",
        "\n",
        "\n",
        "     Если вы с друзьями вместе\n",
        "     Веселитесь во дворе,\n",
        "     А с утра на вас надели\n",
        "     Ваше новое пальто,\n",
        "     То не стоит ползать в лужах\n",
        "     И кататься по земле,\n",
        "     И взбираться на заборы,\n",
        "     Повисая на гвоздях.\n",
        "     Чтоб не портить и не пачкать Ваше новое пальто,\n",
        "     Нужно сделать его старым.\n",
        "     Это делается так:\n",
        "\n",
        "     Залезайте прямо в лужу,\n",
        "     Покатайтесь по земле,\n",
        "     И немножко на заборе\n",
        "     Повисите на гвоздях.\n",
        "     Очень скоро станет старым\n",
        "     Ваше новое пальто,\n",
        "     Вот теперь спокойно можно\n",
        "     Веселиться во дворе.\n",
        "     Можно смело ползать в лужах\n",
        "     И кататься по земле,\n",
        "     И взбираться на заборы,\n",
        "     Повисая на гвоздях.\n",
        "\n",
        "\n",
        "     Если вы по коридору\n",
        "     Мчитесь на велосипеде,\n",
        "     А навстречу вам из ванной\n",
        "     Вышел папа погулять,\n",
        "     Не сворачивайте в кухню,\n",
        "     В кухне - твердый холодильник.\n",
        "     Тормозите лучше в папу.\n",
        "     Папа мягкий. Он простит.\n",
        "\n",
        "\n",
        "     Если вас навек сплотили,\n",
        "     Озарили и ведут,\n",
        "     Не пытайтесь уклониться\n",
        "     От движенья к торжеству.\n",
        "     Все равно на труд поднимет\n",
        "     И на подвиг вдохновит\n",
        "     Вас великий и могучий,\n",
        "     И надежный наш оплот.\n",
        "\n",
        "\n",
        "     Главным делом жизни вашей\n",
        "     Может стать любой пустяк.\n",
        "     Надо только твердо верить,\n",
        "     Что важнее дела нет.\n",
        "     И тогда не помешает\n",
        "     Вам ни холод, ни жара,\n",
        "     Задыхаясь от восторга,\n",
        "     Заниматься чепухой.\n",
        "\n",
        "\n",
        "     Бейте палками лягушек.\n",
        "     Это очень интересно.\n",
        "     Отрывайте крылья мухам,\n",
        "     Пусть побегают пешком.\n",
        "     Тренируйтесь ежедневно,\n",
        "     И наступит день счастливый -\n",
        "     Вас в какое-нибудь царство\n",
        "     Примут главным палачом.\n",
        "\n",
        "     Девчонок надо никогда\n",
        "     Нигде не замечать.\n",
        "     И не давать прохода им\n",
        "     Нигде и никогда.\n",
        "     Им надо ножки подставлять,\n",
        "     Пугать из-за угла,\n",
        "     Чтоб сразу поняли они:\n",
        "     До них вам дела нет.\n",
        "     Девчонку встретил - быстро ей\n",
        "     Показывай язык.\n",
        "     Пускай не думает она,\n",
        "     Что ты в нее влюблен.\n",
        "\n",
        "\n",
        "     Начиная драку с папой,\n",
        "     Затевая с мамой бой,\n",
        "     Постарайся сдаться маме, -\n",
        "     Папа пленных не берет.\n",
        "     Кстати, выясни у мамы,\n",
        "     Не забыла ли она -\n",
        "     Пленных бить ремнем по попе\n",
        "     Запрещает Красный Крест.\n",
        "\n",
        "\n",
        "     Если ты весь мир насилья\n",
        "     Собираешься разрушить,\n",
        "     И при этом стать мечтаешь\n",
        "     Всем, не будучи ничем,\n",
        "     Смело двигайся за нами\n",
        "     По проложенной дороге,\n",
        "     Мы тебе дорогу эту\n",
        "     Можем даже уступить.\n",
        "\n",
        "\n",
        "     Не соглашайся ни за что\n",
        "     Ни с кем и никогда,\n",
        "     А кто с тобой согласен, тех\n",
        "     Трусливыми зови.\n",
        "     За это все тебя начнут\n",
        "     Любить и уважать.\n",
        "     И всюду будет у тебя\n",
        "     Полным полно друзей.\n",
        "\n",
        "\n",
        "     Если в кухне тараканы\n",
        "     Маршируют по столу,\n",
        "     И устраивают мыши\n",
        "     На полу учебный бой,\n",
        "     Значит, вам пора на время\n",
        "     Прекратить борьбу за мир,\n",
        "     И все силы ваши бросить\n",
        "     На борьбу за чистоту.\n",
        "\n",
        "\n",
        "     Если вы собрались другу\n",
        "     Рассказать свою беду,\n",
        "     Брать за пуговицу друга\n",
        "     Бесполезно - убежит,\n",
        "     И на память вам оставит\n",
        "     Эту пуговицу друг.\n",
        "     Лучше дать ему подножку,\n",
        "     На пол бросить, сверху сесть\n",
        "     И тогда уже подробно\n",
        "     Рассказать свою беду.\n",
        "\n",
        "     Если ты пришел к знакомым,\n",
        "     Не здоровайся ни с кем.\n",
        "     Слов: \"пожалуйста\", \"спасибо\"\n",
        "     Никому не говори.\n",
        "     Отвернись и на вопросы\n",
        "     Ни на чьи не отвечай.\n",
        "     И тогда никто не скажет\n",
        "     Про тебя, что ты болтун.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4XQqQgrJoXB3"
      },
      "id": "4XQqQgrJoXB3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'train_dataset.txt'\n",
        "with open(train_path, \"wb\") as f:\n",
        "  f.write(text.encode('utf-8'))\n",
        "\n",
        "train_dataset = TextDataset( tokenizer=tokenizer,file_path=train_path,block_size=64, \n",
        "                            overwrite_cache=True)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWwH9eUepcV2",
        "outputId": "4f7e188c-0fce-4659-ed4e-eefdc0775fc9"
      },
      "id": "eWwH9eUepcV2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments( \n",
        "    output_dir= \"./finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=100, \n",
        "    per_device_train_batch_size=32, \n",
        "    per_device_eval_batch_size=32,  \n",
        "    gradient_accumulation_steps=16, \n",
        "    )\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None) # Optimizer and lr scheduler\n",
        ")"
      ],
      "metadata": {
        "id": "Ryw5EUGsphQk"
      },
      "id": "Ryw5EUGsphQk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax7FMPpCprLf",
        "outputId": "52249be3-6fd7-4fb2-fd7f-9afcc5a650d8"
      },
      "id": "ax7FMPpCprLf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_runtime': 53.9622, 'train_samples_per_second': 46.329, 'train_steps_per_second': 1.853, 'train_loss': 0.09425873756408691, 'epoch': 100.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=0.09425873756408691, metrics={'train_runtime': 53.9622, 'train_samples_per_second': 46.329, 'train_steps_per_second': 1.853, 'train_loss': 0.09425873756408691, 'epoch': 100.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Дождь идет \"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids, \n",
        "                        do_sample=True,\n",
        "                        num_beams=5, top_k=50,\n",
        "                        max_length=300,\n",
        "                        repetition_penalty=3.5\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q341mDampukt",
        "outputId": "25a7bbe0-ac27-4208-a006-42ee28ce75bd"
      },
      "id": "q341mDampukt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Дождь идет \n",
            "     По лужам и лужам,\n",
            "     Повисая на гвоздях.\n",
            "     Если вы с друзьями вместе\n",
            "     Веселитесь во дворе,\n",
            "     Не мешайте им веселиться.\n",
            "     Пусть они веселятся со своим папой\n",
            "     Вместе с вами.\n",
            "\n",
            "\n",
            "     Если у вас в квартире тараканы\n",
            "     Маршируют по потолку,\n",
            "     То не стоит ползать в лужах.\n",
            "     Лучше займитесь генеральной уборкой\n",
            "     Вашей новой квартиры.\n",
            "     Это избавит вас от необходимости каждый день\n",
            "     Убираться в своей квартире.\n",
            "     А заодно и от лишних хлопот.\n",
            "\n",
            "\n",
            "     Если вы все время куда-то торопитесь,\n",
            "     То лучше всего пешком\n",
            "     Доехать до ближайшей железнодорожной станции.\n",
            "     Там вам предложат какой-нибудь интересный\n",
            "     Экскурсионный маршрут.\n",
            "     Например, по железнодорожному полотну\n",
            "     Вы покатаетесь на велосипеде.\n",
            "     А потом пройдете несколько остановок\n",
            "     В разных концах города.\n",
            "     Можно даже взять напрокат велосипед.\n",
            "     Кстати, если вы всей семьей\n",
            "     Прогуляетесь по заснеженному полю\n",
            "     Под открытым небом, то обязательно\n",
            "     Вас за это угостят конфетами.\n",
            "     Так что не стесняйтесь приглашать\n",
            "     На эту прогулку своих друзей.\n",
            "     Им будет очень интересно посмотреть,\n",
            "     Как вы катаетесь на велосипеде.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Текст с параметрами из семинара звучит неплохо, но во втором \"стишке\" фразы почти неизмененные из оригинального текста(\n"
      ],
      "metadata": {
        "id": "BGPHR9IAqYtz"
      },
      "id": "BGPHR9IAqYtz"
    },
    {
      "cell_type": "code",
      "source": [
        "# уменьшила top_k, вместо repetition penalty запретила повторять биграммы\n",
        "\n",
        "text = \"Если ты не хочешь в школу\"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids, \n",
        "                        do_sample=True,\n",
        "                        num_beams=5, \n",
        "                        top_k=30,\n",
        "                        max_length=150,\n",
        "                        no_repeat_ngram_size=2\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "bl7ioJLfsK1g",
        "outputId": "85a2880a-3bdf-461a-81ef-2a8d78ee43fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bl7ioJLfsK1g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Если ты не хочешь в школу опоздать,\n",
            "     Не ходи туда, где тебя ждут.     Там тебя никто не ждет.\n",
            "\n",
            "Прогуливаясь по Невскому проспекту, вы заметили на бортике фонтана трех лягушек. Подбежав к ним, лягушки спрятались под скамейку и стали ждать, пока вы их позовете на помощь. Но когда вы подошли к лягушкам поближе, то увидели, что они уже не прячутся, а ползут к вам на брюках. Помогите им выбраться из лужи. Это очень просто. Нужно просто сказать: \"Лягушки, вылезайте на берег, я вас оттуда достану\". И тогда вы сразу же почувствуете себя уверенными в своих силах\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мне очень нравятся оба варианта)"
      ],
      "metadata": {
        "id": "mEZanhpUt_VD"
      },
      "id": "mEZanhpUt_VD"
    },
    {
      "cell_type": "code",
      "source": [
        "# увеличила число пучков, немного увеличила top k\n",
        "\n",
        "text = \"Если ты\"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids, \n",
        "                        do_sample=True,\n",
        "                        num_beams=7, \n",
        "                        top_k=40,\n",
        "                        max_length=150,\n",
        "                        no_repeat_ngram_size=2\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "tZBuOXTXubCn",
        "outputId": "fa31fe28-7aa8-4859-b39b-61309e98c685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tZBuOXTXubCn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Если ты не с нами,\n",
            "     Не с теми, за кого себя выдаешь.     И если с тобой что-то не так - \n",
            "Повисай на гвоздях до скончания века.\n",
            "\n",
            "Не устраивай крика, не кричи: \"Я с вами, потому что мы рядом\" - и все у тебя будет в порядке. \n",
            "\n",
            "Тебе кажется, что ты один на всем белом свете.  А на самом деле вокруг тебя сплошные враги и завистники. Отведи глаза в сторону и улыбнись им. И тогда они обязательно улыбнутся тебе в ответ. А еще лучше - просто кивни им головой, как это делают дети, когда им показывают мультики про папу Карло и маму\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь, кажется, довольно связно, но пугающе"
      ],
      "metadata": {
        "id": "ElIyMzfBvXJ4"
      },
      "id": "ElIyMzfBvXJ4"
    },
    {
      "cell_type": "code",
      "source": [
        "# убрала пучки, немного увеличила top k, запретила повторять триграммы\n",
        "\n",
        "text = \"Если ты\"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids, \n",
        "                        do_sample=True,\n",
        "                        top_k=60,\n",
        "                        max_length=150,\n",
        "                        temperature = 0.4,\n",
        "                        no_repeat_ngram_size=3\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "m0ZdSueUvd6v",
        "outputId": "1b72642e-b5c1-4074-88ba-b834d0e0ef5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m0ZdSueUvd6v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Если ты с мамой вместе,\n",
            "     Не мешай папе с мамой жить.\n",
            "     И вообще, не мешай маме жить,\n",
            "    А то папа с мамой поссорились.\n",
            "\n",
            "\n",
            "     Если ты с папой вместе, -\n",
            "     Учись хорошо плавать,\n",
            "   А не то утонешь.\n",
            "   И вообще - не мешайте папе\n",
            "     Заниматься ерундой.\n",
            "    Папа с мамой любят поговорить\n",
            "     О пустяках.\n",
            "  Если ты папе не веришь,\n",
            "         Объясни ему, что это -\n",
            "         Папа тебе маму испортил.\n",
            "         И вообще:\n",
            "     Папа всех переплюнет.\n",
            " \n",
            "\n",
            "     Никогда не спорь с папой\n",
            "     Ни за что. Он очень хитрый\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кажется, даже немного похоже по смыслу на вредные советы)"
      ],
      "metadata": {
        "id": "yF9X0euyw-TW"
      },
      "id": "yF9X0euyw-TW"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"Если вам слегка за двадцать\"\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model.generate(input_ids, \n",
        "                        do_sample=True,\n",
        "                        top_k=60,\n",
        "                        max_length=150,\n",
        "                        temperature = 0.4,\n",
        "                        no_repeat_ngram_size=3\n",
        "                        )\n",
        "\n",
        "generated_text = list(map(tokenizer.decode, out))[0]\n",
        "print()\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "GJmqrhmKxLhd",
        "outputId": "769555fc-f985-4862-ffc3-ee7b5e85edd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GJmqrhmKxLhd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Если вам слегка за двадцать,\n",
            "     Не стоит отчаиваться.\n",
            "     Вам помогут друзья.\n",
            "\n",
            "\n",
            "     Если вы на работе одни,\n",
            "    Не устраивайте крика,\n",
            "   Дайте спокойно отдохнуть.\n",
            "    И спокойно все вокруг\n",
            "     Переварите.\n",
            "   И спокойно на работе\n",
            "     Повисайте.\n",
            "  И не мешайте работе\n",
            "    До победного конца.\n",
            " \n",
            "\n",
            "     Когда вам немного за тридцать,\n",
            "  Не стоит расстраиваться.\n",
            "         Это всего лишь возраст.\n",
            "                 Может статься, что вы\n",
            "     Совсем не изменились.\n",
            "_______________\n",
            "\n",
            "  Если вам немного под сорок,\n",
            "         Не стоит впадать в панику.\n",
            "Потерявшийся ребенок\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ну и немного позитива от модели)"
      ],
      "metadata": {
        "id": "3bVcaluVyflG"
      },
      "id": "3bVcaluVyflG"
    },
    {
      "cell_type": "markdown",
      "id": "ae8437e8",
      "metadata": {
        "id": "ae8437e8"
      },
      "source": [
        "### Задание  2 (2 балла)\n",
        "\n",
        "Ответьте на следующие вопросы:\n",
        "\n",
        "1) В каких статья были представлены GPT-1, GPT-2, GPT-3?\n",
        "\n",
        "2) Как собирался обучающий корпус для GPT-3? Каким образом создатели старались обеспечить высокое качество текстов в обучающей выборке?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос 1**\n",
        "- GPT-1: Improving Language Understanding by Generative Pre-Training (2018) (https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n",
        "- GPT-2: Language Models are Unsupervised Multitask Learners (2019) (https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
        "- GPT-3: Language Models are Few-Shot Learners (2020) (https://arxiv.org/pdf/2005.14165.pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "5m3nW7DTz-w2"
      },
      "id": "5m3nW7DTz-w2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вопрос 2**\n",
        "\n",
        "Основной датасет, на котором обучался GPT-3 - Common Crawl, состоящий практически из триллиона токенов. Он был создан путем многолетнего (с 2008 года) веб-краулинга огромного числа страниц в интернете.\n",
        "\n",
        "Чтобы повысить качество текстов, подающихся на обучение модели, этот датасет был отфильтрован: были взяты несколько менее крупных, но качественных корпусов, таких как корпус англоязычной википедии и книжные корпуса, и Common Crawl был отфильтрован на основе сходства с ними. Эти корпуса также были добавлены в обучающую выборку. \n",
        "\n",
        "Кроме того, к корпусу на уровне документов была применена дедупликация, чтобы предотвратить повторы и избыточность, а данные брались не за все время, а только за период 2016-2019 годов. Итоговый объем копуса: 410 миллиардов токенов.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BV3ieDp12171"
      },
      "id": "BV3ieDp12171"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}